# -*- coding: utf-8 -*-
"""mlcode_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K11s_P-ig1mdMHnZmm0bV3oXLsd2iyN3

Please download and load the data file by clicking <a href="https://github.com">here</a> before executing the following code.

## **Import packages**
"""

import tensorflow as tf
!pip install xgboost
import xgboost as xgb
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import zscore
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from xgboost import plot_tree
!pip install graphviz
import graphviz

"""## **Using CNN without amino acids (Mixed sampling)**

#### **Using all data except allowed/disallowed**
"""

# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')
# Split the data into features (X) and labels (y)
X_tr = data[:, [9, 10, 11, 12, 13, 14]]

y_tr = data[:,0]

X_train1 = X_tr[100:]
X_test1 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]

# Apply Z-score normalization to each column
X_train = zscore(X_train1, axis=0)
X_test = zscore(X_test1, axis=0)

# Create the CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(6,)),
    tf.keras.layers.Dense(units=128, activation='relu'),
    #tf.keras.layers.Dense(units=32, activation='relu'),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dense(units=8, activation='relu'),
    #tf.keras.layers.Dense(units=2, activation='relu'),
    tf.keras.layers.Dense(units=1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))

# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]

# Calculate accuracy of the model
accuracy = accuracy_score(y_test, y_pred_binary)
print(f'Accuracy: {accuracy}')

y_pred_binary = np.array(y_pred_binary)


# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")

# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred)

# Calculate the area under the ROC curve (AUC)
roc_auc = auc(fpr, tpr)

"""#### **Using all data with allowed/disallowed**"""

# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')
# Split the data into features (X) and labels (y)
X_tr = data[:, [1, 9, 10, 11, 12, 13, 14]]

y_tr = data[:,0]

X_train2 = X_tr[100:]
X_test2 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]

# Apply Z-score normalization to each column
X_train = zscore(X_train2, axis=0)
X_test = zscore(X_test2, axis=0)

# Create the CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(7,)),
    tf.keras.layers.Dense(units=128, activation='relu'),
    #tf.keras.layers.Dense(units=32, activation='relu'),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dense(units=8, activation='relu'),
    #tf.keras.layers.Dense(units=2, activation='relu'),
    tf.keras.layers.Dense(units=1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))

# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]

# Calculate accuracy of the model
accuracy = accuracy_score(y_test, y_pred_binary)
print(f'Accuracy: {accuracy}')

y_pred_binary = np.array(y_pred_binary)

# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")

# Mixed Sampling


# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr1, tpr1, thresholds1 = roc_curve(y_test, y_pred)

# Calculate the area under the ROC curve (AUC)
roc_auc1 = auc(fpr1, tpr1)

# Plot the ROC curve
plt.figure()
plt.plot(fpr1, tpr1, color='#E7B800', lw=2, label='with conf (area = %0.2f)' % roc_auc1)
plt.plot(fpr, tpr, color='#00AFBB', lw=2, label='without conf (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")

plt.savefig('CNN_mixedsampling.png', dpi=300)
plt.show()

# Calculate baseline accuracy
y_pred = model.predict(X_test)
y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]
baseline_accuracy = accuracy_score(y_test, y_pred_binary)

# Calculate feature importance using permutation importance
num_permutations = 100
feature_importance = np.zeros(X_test.shape[1])

for feature in range(X_test.shape[1]):
    X_test_permuted = X_test.copy()
    np.random.shuffle(X_test_permuted[:, feature])
    y_pred_permuted = model.predict(X_test_permuted)
    y_pred_binary_permuted = [1 if p >= 0.5 else 0 for p in y_pred_permuted]
    permuted_accuracy = accuracy_score(y_test, y_pred_binary_permuted)
    feature_importance[feature] = baseline_accuracy - permuted_accuracy

# Normalize feature importance
feature_importance /= np.sum(feature_importance)

# Print feature importance
for i, importance in enumerate(feature_importance):
    print(f'Feature {i+1} importance: {importance}')

"""## **Using CNN with amino acids (Mixed sampling)**

#### **Using all data except allowed/disallowed**
"""

# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')
# Split the data into features (X) and labels (y)
X_tr = data[:, [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]

y_tr = data[:,0]

X_train1 = X_tr[100:]
X_test1 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]

# Apply Z-score normalization to each column
X_train = zscore(X_train1, axis=0)
X_test = zscore(X_test1, axis=0)

# Create the CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(26,)),
    #tf.keras.layers.Dense(units=128, activation='relu'),
    tf.keras.layers.Dense(units=32, activation='relu'),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dense(units=8, activation='relu'),
    #tf.keras.layers.Dense(units=2, activation='relu'),
    tf.keras.layers.Dense(units=1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))

# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]

# Calculate accuracy of the model
accuracy = accuracy_score(y_test, y_pred_binary)
print(f'Accuracy: {accuracy}')

y_pred_binary = np.array(y_pred_binary)


# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")

# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred)

# Calculate the area under the ROC curve (AUC)
roc_auc = auc(fpr, tpr)

"""#### **Using all data with allowed/disallowed**"""

# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')
# Split the data into features (X) and labels (y)
X_tr = data[:, [1, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]

y_tr = data[:,0]

X_train2 = X_tr[100:]
X_test2 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]

# Apply Z-score normalization to each column
X_train = zscore(X_train2, axis=0)
X_test = zscore(X_test2, axis=0)

# Create the CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(27,)),
    #tf.keras.layers.Dense(units=128, activation='relu'),
    tf.keras.layers.Dense(units=32, activation='relu'),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dense(units=8, activation='relu'),
    #tf.keras.layers.Dense(units=2, activation='relu'),
    tf.keras.layers.Dense(units=1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))

# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]

# Calculate accuracy of the model
accuracy = accuracy_score(y_test, y_pred_binary)
print(f'Accuracy: {accuracy}')

y_pred_binary = np.array(y_pred_binary)

# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")

# Mixed Sampling


# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr1, tpr1, thresholds1 = roc_curve(y_test, y_pred)

# Calculate the area under the ROC curve (AUC)
roc_auc1 = auc(fpr1, tpr1)

# Plot the ROC curve
plt.figure()
plt.plot(fpr1, tpr1, color='#E7B800', lw=2, label='with conf (area = %0.2f)' % roc_auc1)
plt.plot(fpr, tpr, color='#00AFBB', lw=2, label='without conf (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")

plt.savefig('CNN_mixedsampling.png', dpi=300)
plt.show()

# Calculate baseline accuracy
y_pred = model.predict(X_test)
y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]
baseline_accuracy = accuracy_score(y_test, y_pred_binary)

# Calculate feature importance using permutation importance
num_permutations = 100
feature_importance = np.zeros(X_test.shape[1])

for feature in range(X_test.shape[1]):
    X_test_permuted = X_test.copy()
    np.random.shuffle(X_test_permuted[:, feature])
    y_pred_permuted = model.predict(X_test_permuted)
    y_pred_binary_permuted = [1 if p >= 0.5 else 0 for p in y_pred_permuted]
    permuted_accuracy = accuracy_score(y_test, y_pred_binary_permuted)
    feature_importance[feature] = baseline_accuracy - permuted_accuracy

# Normalize feature importance
feature_importance /= np.sum(feature_importance)

# Print feature importance
for i, importance in enumerate(feature_importance):
    print(f'Feature {i+1} importance: {importance}')

"""## **XgBoost Without amino acids (Mixed sampling)**"""

import xgboost as xgb

# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')

# Split the data into features (X) and labels (y)
X_tr = data[:, [7, 9, 10, 11, 12, 13, 14]
]
y_tr = data[:,0]

X_train1 = X_tr[100:]
X_test1 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]

# Apply Z-score normalization to each column
X_train = zscore(X_train1, axis=0)
X_test = zscore(X_test1, axis=0)

# Convert the data into DMatrix format for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)


# Set the XGBoost parameters
params = {
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    'learning_rate': 0.1,
    'max_depth': 5,
    'reg_alpha': 0.007,
    'reg_lambda': 0.1,
    'gamma': 0.5
}


# Train the XGBoost model
num_rounds = 100
xgb_model = xgb.train(params, dtrain, num_rounds)

# Obtain predicted probabilities for the positive class
y_pred_proba = xgb_model.predict(dtest)

letpara = ['allow_dis', 'asa_surface', 'foldX_ddG', 'normScore', 'address_contact', 'hbond', 'modeller_short_contact']

# Get the graphviz representation of the first tree
xgb_tree = xgb.to_graphviz(xgb_model, num_trees=0)

# Get the DOT source code from the graphviz tree
dot_source = xgb_tree.source

# Modify the node labels in the DOT source code
for feature_index, feature_name in enumerate(letpara):
    dot_source = dot_source.replace(f'f{feature_index}', feature_name)

# Create a new graphviz.Source object with the modified DOT source code
modified_tree = graphviz.Source(dot_source)
#print(modified_tree)
# Render and display the modified tree
modified_tree.format = 'png'
modified_tree.render('xgboost_tree_mixedsampling_0', view=True)

'''
# plot single tree
plot_tree(xgb_model)
plt.savefig('xgboost_mixedsamplingtree1.png', dpi=300)
plt.show()
'''

# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Calculate the area under the ROC curve (AUC)
roc_auc = auc(fpr, tpr)

#############



y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred_proba]

y_pred_binary = np.array(y_pred_binary)

# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")





################

##############################################



# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')

# Split the data into features (X) and labels (y)
#X_tr = data[:, [4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]]
X_tr = data[:, [1, 9, 10, 11, 12, 13, 14]
]
y_tr = data[:,0]

X_train1 = X_tr[100:]
X_test1 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]


# Apply Z-score normalization to each column
X_train = zscore(X_train1, axis=0)
X_test = zscore(X_test1, axis=0)


# Convert the data into DMatrix format for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)


# Set the XGBoost parameters
params = {
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    'learning_rate': 0.1,
    'max_depth': 5,
    'reg_alpha': 0.007,
    'reg_lambda': 0.1,
    'gamma': 0.5
}


# Train the XGBoost model
num_rounds = 100
xgb_model = xgb.train(params, dtrain, num_rounds)

letpara1 = ['allow_dis', 'asa_surface', 'foldX_ddG', 'normScore', 'address_contact', 'hbond', 'modeller_short_contact']

# Get the graphviz representation of the first tree
xgb_tree = xgb.to_graphviz(xgb_model, num_trees=1)

# Get the DOT source code from the graphviz tree
dot_source = xgb_tree.source

# Modify the node labels in the DOT source code
for feature_index, feature_name in enumerate(letpara1):
    dot_source = dot_source.replace(f'f{feature_index}', feature_name)

# Create a new graphviz.Source object with the modified DOT source code
modified_tree = graphviz.Source(dot_source)

# Render and display the modified tree
modified_tree.format = 'png'
modified_tree.render('xgboost_tree_mixedsampling_1', view=True)
#print(modified_tree)

'''
# plot single tree
plot_tree(xgb_model)
plt.savefig('xgboost_mixedsamplingtree2.png', dpi=300)
plt.show()
'''
# Obtain predicted probabilities for the positive class
y_pred_proba = xgb_model.predict(dtest)
#############



y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred_proba]

y_pred_binary = np.array(y_pred_binary)

# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")


#####################################


# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr3, tpr3, thresholds3 = roc_curve(y_test, y_pred_proba)

# Calculate the area under the ROC curve (AUC)
roc_auc3 = auc(fpr3, tpr3)

# Plot the ROC curve
plt.figure()
plt.plot(fpr3, tpr3, color='#E7B800', lw=2, label='with conf (area = %0.2f)' % roc_auc3)
plt.plot(fpr, tpr, color='#00AFBB', lw=2, label='without conf (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")

plt.savefig('xgboost_mixedsampling.png', dpi=1000)
plt.show()

"""## **XgBoost With amino acids (Mixed sampling)**"""

import xgboost as xgb

# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')

# Split the data into features (X) and labels (y)
X_tr = data[:, [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]
#X_tr = data[:, [9, 10, 11, 12, 13, 14]]

y_tr = data[:,0]

X_train1 = X_tr[100:]
X_test1 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]

# Apply Z-score normalization to each column
X_train = zscore(X_train1, axis=0)
X_test = zscore(X_test1, axis=0)

# Convert the data into DMatrix format for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)


params = {
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    'learning_rate': 0.1,
    'max_depth': 8,
    'reg_alpha': 0.001,
    'reg_lambda': 0.1,
    'gamma': 0.6

}



# Train the XGBoost model
num_rounds = 100
xgb_model = xgb.train(params, dtrain, num_rounds)

# Obtain predicted probabilities for the positive class
y_pred_proba = xgb_model.predict(dtest)

letpara = ['asa_surface', 'foldX_ddG', 'normScore', 'address_contact', 'hbond', 'modeller_short_contact', 'A',	'C', 'D', 'E', 'F', 'G', 'H',	'I', 'K',	'L', 'M',	'N', 'P',	'Q', 'R', 'S', 'T',	'V', 'W', 'Y']

# Get the graphviz representation of the first tree
xgb_tree = xgb.to_graphviz(xgb_model, num_trees=0)

# Get the DOT source code from the graphviz tree
dot_source = xgb_tree.source

# Modify the node labels in the DOT source code
for feature_index, feature_name in enumerate(letpara):
    dot_source = dot_source.replace(f'f{feature_index}', feature_name)

# Create a new graphviz.Source object with the modified DOT source code
modified_tree = graphviz.Source(dot_source)
#print(modified_tree)
# Render and display the modified tree
modified_tree.format = 'png'
modified_tree.render('xgboost_tree_mixedsampling_0', view=True)

# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Calculate the area under the ROC curve (AUC)
roc_auc = auc(fpr, tpr)

#############



y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred_proba]

y_pred_binary = np.array(y_pred_binary)

# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")





################

##############################################



# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')

# Split the data into features (X) and labels (y)
X_tr = data[:, [1, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]
#X_tr = data[:, [1, 9, 10, 11, 12, 13, 14]]

y_tr = data[:,0]

X_train1 = X_tr[100:]
X_test1 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]


# Apply Z-score normalization to each column
X_train = zscore(X_train1, axis=0)
X_test = zscore(X_test1, axis=0)


# Convert the data into DMatrix format for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

params = {
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    'learning_rate': 0.1,
    'max_depth': 8,
    'reg_alpha': 0.001,
    'reg_lambda': 0.1,
    'gamma': 0.6

}

# Train the XGBoost model , 'A',	'C', 'D', 'E', 'F', 'G', 'H',	'I', 'K',	'L', 'M',	'N', 'P',	'Q', 'R', 'S', 'T',	'V', 'W', 'Y'
num_rounds = 100
xgb_model = xgb.train(params, dtrain, num_rounds)

letpara1 = ['allowed_disa', 'asa_surface', 'foldX_ddG', 'normScore', 'address_contact', 'hbond', 'modeller_short_contact', 'A',	'C', 'D', 'E', 'F', 'G', 'H',	'I', 'K',	'L', 'M',	'N', 'P',	'Q', 'R', 'S', 'T',	'V', 'W', 'Y']

# Get the graphviz representation of the first tree
xgb_tree = xgb.to_graphviz(xgb_model, num_trees=1)

# Get the DOT source code from the graphviz tree
dot_source = xgb_tree.source

# Modify the node labels in the DOT source code
for feature_index, feature_name in enumerate(letpara1):
    dot_source = dot_source.replace(f'f{feature_index}', feature_name)

# Create a new graphviz.Source object with the modified DOT source code
modified_tree = graphviz.Source(dot_source)

# Render and display the modified tree
modified_tree.format = 'png'
modified_tree.render('xgboost_tree_mixedsampling_1', view=True)
#print(modified_tree)

# Obtain predicted probabilities for the positive class
y_pred_proba = xgb_model.predict(dtest)
#############



y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred_proba]

y_pred_binary = np.array(y_pred_binary)

# Calculate the true positives, false positives, true negatives, and false negatives

true_positives = np.sum((y_pred_binary == 1) & (y_test == 1))
false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))
true_negatives = np.sum((y_pred_binary == 0) & (y_test == 0))
false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))

# Create the table
table = [
    ["True Positives", true_positives],
    ["False Positives", false_positives],
    ["True Negatives", true_negatives],
    ["False Negatives", false_negatives]
]

# Calculate the maximum width of the first column
max_width = max(len(row[0]) for row in table)

# Print the table
print("Confusion Matrix:")
print("-----------------")
for row in table:
    print(f"{row[0]:<{max_width}} | {row[1]}")

print("-----------------")
# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred_binary)
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
f1 = f1_score(y_test, y_pred_binary)

# Print the evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("-----------------")


#####################################


# Calculate the false positive rate (FPR) and true positive rate (TPR) for the ROC curve
fpr3, tpr3, thresholds3 = roc_curve(y_test, y_pred_proba)

# Calculate the area under the ROC curve (AUC)
roc_auc3 = auc(fpr3, tpr3)

# Plot the ROC curve
plt.figure()
plt.plot(fpr3, tpr3, color='#E7B800', lw=2, label='with conf (area = %0.2f)' % roc_auc3)
plt.plot(fpr, tpr, color='#00AFBB', lw=2, label='without conf (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")

plt.savefig('xgboost_mixedsampling_AA.png', dpi=1000)
plt.show()

"""## **Code to find optimum parameters for XgBoost (Optional)**"""

# Load the training data from a text file
data = np.loadtxt('/content/mixfinal.txt')

# Split the data into features (X) and labels (y)
X_tr = data[:, [1, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]]
#X_tr = data[:, [1, 9, 10, 11, 12, 13, 14]]

y_tr = data[:,0]

X_train1 = X_tr[100:]
X_test1 = X_tr[:100]
y_train = y_tr[100:]
y_test = y_tr[:100]


# Apply Z-score normalization to each column
X_train = zscore(X_train1, axis=0)
X_test = zscore(X_test1, axis=0)

# Define the parameter distributions for randomized search
param_dist = {
    'objective': ['binary:logistic'],
    'eval_metric': ['logloss'],
    'learning_rate': [0.1],
    'max_depth': [5,7,6,8],
    'reg_alpha': [0.007, 0.1, 1.0, 10.0, 0.01, 0.001],
    'reg_lambda': [0.01, 0.1, 1.0, 10.0],
    'gamma': [0, 0.1, 0.5, 1.0, 0.01, 0.6]
}


# Create an XGBoost classifier
xgb_model1 = xgb.XGBClassifier()

# Perform randomized search with cross-validation
random_search1 = RandomizedSearchCV(xgb_model1, param_dist, n_iter=10, scoring='accuracy', cv=5)
random_search1.fit(X_train, y_train)

# Get the best parameter values and the corresponding model
best_params = random_search1.best_params_
best_model = random_search1.best_estimator_

# Print the best parameter values
print("Best Parameter Values:")
for param, value in best_params.items():
    print(f"{param}: {value}")


# Evaluate the best model on the validation set
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Best Model Accuracy: {accuracy}")

# Train the final model on the entire dataset using the best parameters
final_model = xgb.XGBClassifier(**best_params)
final_model.fit(X_train, y_train)

"""## **Getting feature importance (Optional)**"""

y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred_proba]

# Calculate accuracy of the model
accuracy = accuracy_score(y_test, y_pred_binary)
print(f'Accuracy: {accuracy}')

# Get feature importance
importance = xgb_model.get_score(importance_type='gain')
sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)

# Print feature importance
print("Feature Importance:")
for feature, importance_score in sorted_importance:
    print(f'Feature {feature}: {importance_score}')